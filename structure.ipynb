{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring End-to-End Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Path to your API key file\n",
    "api_key_file_path = '/Users/dylan/Documents/AIEng1/newAPI.txt'\n",
    "\n",
    "# Read the API key from the file\n",
    "with open(api_key_file_path, 'r') as file:\n",
    "    de_api_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=de_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important to specify in the messages the response format\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": \"How many hours to learn Spanish? and how many weeks does that take if I study 10 h/w? What level on the EU framework will I be? Please respons in json format.\"}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hours_to_learn\": \"600 hours\",\n",
      "  \"weeks_to_learn\": \"60 weeks\",\n",
      "  \"study_hours_per_week\": 10,\n",
      "  \"eu_framework_level\": \"B1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "- Connection issues, check connection, reach out\n",
    "- Resource limits errors, conflict, ratelimit -- check amount being pushed\n",
    "- Authentications - \n",
    "- Bad Request - missing or invalid parameteres \n",
    "\n",
    "\n",
    "Try and except blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"List five data science professions.\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "except openai.AuthenticationError as e:\n",
    "    print(f\"OpenAI API failed to authenticate: {e}\")\n",
    "    pass\n",
    "except openai.RateLimitError as e:\n",
    "    print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    "    pass\n",
    "except Exception as e:\n",
    "    print(f\"Unable to generate a response. Exception: {e}\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching\n",
    "\n",
    "- Solving rate limit error \n",
    "- Setting a short pause\n",
    "- Processing multiple messages in one request (batching)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (22319831.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6)),\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tenacity import(\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential\n",
    ")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are two color pairings for a shirt and jacket:\n",
      "\n",
      "1. Shirt: Light blue Jacket: Navy blue\n",
      "2. Shirt: White Jacket: Olive green\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "client = OpenAI(api_key=de_api_key)\n",
    "input_message = {\"role\": \"user\", \"content\": \"I'd like to buy a shirt and a jacket. Can you suggest two color pairings for these items?\"}\n",
    "\n",
    "# Use tiktoken to create the encoding for your model\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "# Check for the number of tokens\n",
    "num_tokens = len(encoding.encode(input_message['content']))\n",
    "\n",
    "# Run the chat completions function and print the response\n",
    "if num_tokens <= 100:\n",
    "    response = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=[input_message])\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"Message exceeds token limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "- We can get rid of inconsistent formats\n",
    "- Calling multiple functions to provide complext systems\n",
    "- Calling external APIs (weather etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"quickest_way_to_learn_spanish\": {\n",
      "    \"methods\": [\n",
      "      {\n",
      "        \"method\": \"Immersion\",\n",
      "        \"description\": \"Surround yourself with Spanish speakers and consume Spanish media (films, music, books) to enhance listening and speaking skills.\"\n",
      "      },\n",
      "      {\n",
      "        \"method\": \"Language Apps\",\n",
      "        \"description\": \"Use apps like Duolingo, Babbel, or Rosetta Stone for structured learning and daily practice.\"\n",
      "      },\n",
      "      {\n",
      "        \"method\": \"Online Courses\",\n",
      "        \"description\": \"Enroll in online courses or tutorials that focus on conversational Spanish and grammar.\"\n",
      "      },\n",
      "      {\n",
      "        \"method\": \"Language Exchange\",\n",
      "        \"description\": \"Partner with a native Spanish speaker who wants to learn your language for mutual practice.\"\n",
      "      },\n",
      "      {\n",
      "        \"method\": \"Flashcards\",\n",
      "        \"description\": \"Utilize flashcards to build vocabulary and reinforce memory through repetition.\"\n",
      "      },\n",
      "      {\n",
      "        \"method\": \"Consistent Practice\",\n",
      "        \"description\": \"Set aside time daily to practice speaking, listening, reading, and writing in Spanish.\"\n",
      "      },\n",
      "      {\n",
      "        \"method\": \"Travel\",\n",
      "        \"description\": \"If possible, travel to a Spanish-speaking country for an immersive experience.\"\n",
      "      }\n",
      "    ],\n",
      "    \"tips\": [\n",
      "      \"Focus on frequently used words and phrases.\",\n",
      "      \"Practice speaking from day one.\",\n",
      "      \"Make mistakes and learn from them.\",\n",
      "      \"Label items around your home in Spanish.\",\n",
      "      \"Join Spanish-speaking communities or clubs.\"\n",
      "    ],\n",
      "    \"goal_setting\": {\n",
      "      \"short_term\": \"Learn basic conversational phrases within a month.\",\n",
      "      \"long_term\": \"Achieve fluency in 6 months to a year with consistent practice.\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": \"Quickest way to learn spanish? repsond in json format\"}\n",
    "        \n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=de_api_key)\n",
    "\n",
    "message_listings = [{'role': 'system', 'content': \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"}, {'role': 'user', 'content': '\\nA. M. Turing (1950) Computing Machinery and Intelligence. Mind 49: 433-460.\\nCOMPUTING MACHINERY AND INTELLIGENCE\\nBy A. M. Turing\\n1. The Imitation Game\\nI propose to consider the question, \"Can machines think?\" This should begin with\\ndefinitions of the meaning of the terms \"machine\" and \"think.\" The definitions might be\\nframed so as to reflect so far as possible the normal use of the words, but this attitude is\\ndangerous, If the meaning of the words \"machine\" and \"think\" are to be found by\\nexamining how they are commonly used it is difficult to escape the conclusion that the\\nmeaning and the answer to the question, \"Can machines think?\" is to be sought in a\\nstatistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a\\ndefinition I shall replace the question by another, which is closely related to it and is\\nexpressed in relatively unambiguous words.\\nThe new form of the problem can be described in terms of a game which we call the\\n\\'imitation game.\" It is played with three people, a man (A), a woman (B), and an\\ninterrogator (C) who may be of either sex. The interrogator stays in a room apart front the\\nother two. The object of the game for the interrogator is to determine which of the other\\ntwo is the man and which is the woman. He knows them by labels X and Y, and at the\\nend of the game he says either \"X is A and Y is B\" or \"X is B and Y is A.\" The\\ninterrogator is allowed to put questions to A and B thus:\\nC: Will X please tell me the length of his or her hair?\\nNow suppose X is actually A, then A must answer. It is A\\'s object in the game to try and\\ncause C to make the wrong identification. His answer might therefore be:\\n\"My hair is shingled, and the longest strands are about nine inches long.\"\\nIn order that tones of voice may not help the interrogator the answers should be written,\\nor better still, typewritten. The ideal arrangement is to have a teleprinter communicating\\nbetween the two rooms. Alternatively the question and answers can be repeated by an\\nintermediary. The object of the game for the third player (B) is to help the interrogator.\\nThe best strategy for her is probably to give truthful answers. She can add such things as\\n\"I am the woman, don\\'t listen to him!\" to her answers, but it will avail nothing as the man\\ncan make similar remarks.\\nWe now ask the question, \"What will happen when a machine takes the part of A in this\\ngame?\" Will the interrogator decide wrongly as often when the game is played like this as\\nhe does when the game is played between a man and a woman? These questions replace\\nour original, \"Can machines think?\\n                 '}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This excerpt is from Alan Turing's seminal paper, \"Computing Machinery and Intelligence,\" where he introduces The Imitation Game, now commonly known as the Turing Test. Turing explores the question of whether machines can think by framing it in terms of a game involving a human interrogator, a man, and a woman. \n",
      "\n",
      "The game challenges the interrogator to distinguish between the two players based solely on their responses to questions. Turing suggests that if a machine can successfully imitate a human in this context, it raises the question of whether we should attribute the capacity to think to machines.\n",
      "\n",
      "If you have specific questions about the text or need further analysis or explanations on certain aspects, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "function_definition = [{\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'extract_job_info',\n",
    "        'description': 'Get the job information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'job': {'type': 'string', 'description': 'Job title'},\n",
    "                'location': {'type': 'string', 'description': 'Location'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=message_listings,\n",
    "    tools = function_definition,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Function Calls\n",
    "\n",
    "\n",
    "Respond to a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=de_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definition = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'extract_sentiment_and_product_features',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'product': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The product name'\n",
    "                    },\n",
    "                    'sentiment': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The overall sentiment of the review'\n",
    "                    },\n",
    "                    'features': {\n",
    "                        'type': 'array',\n",
    "                        'items': {\n",
    "                            'type': 'string'\n",
    "                        },\n",
    "                        'description': 'List of features mentioned in the review'\n",
    "                    },\n",
    "                    'suggestions': {\n",
    "                        'type': 'array',\n",
    "                        'items': {\n",
    "                            'type': 'string'\n",
    "                        },\n",
    "                        'description': 'Suggestions for improvement'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definition.append(\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'reply_to_review',\n",
    "            'description': 'Reply politely to the customer who wrote the review',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'reply': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Reply to post in response to the review'\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': 'Apply both functions and return responses.'},\n",
    "    {'role': 'user', 'content': \"I recently purchased the TechCorp ProMax and I'm absolutely in love with its powerful processor. However, I think they could really improve the product by deciding to offer more color options.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Don't make up values to fill the response with.\"})\n",
    "messages.append({\"role\": \"system\", \"content\": \"Ask for clarification if needed.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reply\":\"Thank you for your review! We appreciate your feedback and are glad you took the time to share your experience with us.\"}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools = function_definition,\n",
    "    tool_choice = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"reply_to_review\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoiding Inconsistency in replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': 'Apply both functions and return responses.'},\n",
    "    {'role': 'user', 'content': 'Thrilled with the quality, but I think it should come with a wider choice of screen sizes.'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Don't make up values to fill the response with.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(messages, function_definition):\n",
    "  response = client.chat.completions.create(\n",
    "      model=\"gpt-4o-mini\",\n",
    "      messages=messages,\n",
    "      tools=function_definition\n",
    "  )\n",
    "  return str(response.choices[0].message.tool_calls[0].function.arguments) + \",\\n \" + str(response.choices[0].message.tool_calls[1].function.arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentiment\": \"Thrilled\", \"features\": [\"Quality\"], \"suggestions\": [\"Wider choice of screen sizes\"]},\n",
      " {\"reply\": \"Thank you for your feedback! We're thrilled to hear you are happy with the quality. We appreciate your suggestion for more screen size options and will take it into consideration.\"}\n"
     ]
    }
   ],
   "source": [
    "response = get_response(messages, function_definition)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling External APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_artwork(keyword):\n",
    "    url = \"https://api.artic.edu/api/v1/artworks/search\"\n",
    "    querystring = {\"q\": keyword}\n",
    "    response = requests.request(\"GET\", url, params=querystring)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an AI assistant, a specialist in history of art. You should interpret the user prompt, and based on it extract one keyword for recommending artwork related to their preference.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I don't have much time to visit the museum and would like some recommendations. I like the seaside and quiet places.\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_definition = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_artwork\",\n",
    "            \"description\": \"This function calls the Art Institute of Chicago API to find artwork that matches a keyword\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"artwork keyword\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The keyword to be passed to the get_artwork function.\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"result\": {\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools = function_definition,\n",
    "    tool_choice='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some recommendations: ['Life-Size Black Bass', 'Figure Screen (Duein Fubara)', 'Screen', 'Marilyn Monroe (Marilyn)', 'Woman at an Easel (Green Screen)', 'Mao', 'Marilyn Monroe (Marilyn)', 'Fire Screen', 'Screen', 'Flowering Cherry and Autumn Maples with Poem Slips']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "if response.choices[0].finish_reason == 'tool_calls':\n",
    "    function_call = response.choices[0].message.tool_calls[0].function\n",
    "    if function_call.name == \"get_artwork\":\n",
    "        artwork_keyword = json.loads(function_call.arguments)[\"artwork keyword\"]\n",
    "        artwork = get_artwork(artwork_keyword)\n",
    "        if artwork:\n",
    "            print(f\"Here are some recommendations: {[i['title'] for i in json.loads(artwork)['data']]}\")\n",
    "        else:\n",
    "            print(\"Apologies, I couldn't make any recommendations based on the request.\")\n",
    "    else:\n",
    "        print(\"Apologies, I couldn't find any artwork.\")\n",
    "else:\n",
    "    print(\"I am sorry, but I could not understand your request.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations\n",
    "\n",
    "- prompt injections\n",
    "\n",
    "\n",
    "elaluation libraries and datasets\n",
    "\n",
    "![Alt text](./Users/dylan/Documents/AIEng1/Screenshot%202024-07-20%20at%2012.58.49.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIEng1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
